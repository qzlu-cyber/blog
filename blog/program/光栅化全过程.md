---
    slug: rasterization
    title: 光栅化全过程
    date: 2023-09-17
    authors: Kaesar
    tags: [CG, Rendering, Rasterization, Rendering Pipeline, Shading, Phong Light Model, Blinn-Phong Light Model, Flat Shading, Gouraud Shading, Phong Shading]
    keywords: [光栅化, 光照模型, 着色模型, 纹理映射, 深度测试]
---

# 光栅化全过程

光栅化是渲染的主要方法之一，负责将要显示的像素（顶点完成变换后得到的屏幕像素坐标）在屏幕上给显示出来。理解整个光栅化的过程后基本可以写出一个简单的软渲染器，比如 [TinyRenderer](https://github.com/ssloy/tinyrenderer)。我跟着这个教程做过两遍，第一次是基本在上完 Games101 后，很多概念掌握不深，草草做过后遗忘的很快；第二次是读了一些资料又学过 OpenGL 后，这次效果好很多，解决了之前一些模糊的概念，也对 OpenGL 的原理有了了解。

### 渲染流水线

![渲染流水线](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309181300811.png)

GPU 渲染流水线接受顶点数据作为输入，之后将这些数据传给顶点着色器进行处理。输入的每个顶点都会调用一次顶点着色器，以完成对顶点的[空间变换](https://qzlu-cyber.netlify.app/blog/transform)。之后进入三角形设置阶段，这个阶段会计算出光栅化一个三角形网格所需的信息。顶点着色器输出的顶点只是网格每条边的顶点，无法得到顶点之间的关系，经过该步骤就可以得到三角形图元的边界在屏幕的表示。随后就进入了光栅化阶段，首先遍历每个三角形来检查像素是否被一个三角形网格所覆盖，如果被覆盖就会生成一个片元（fragment），片元包含一个像素的很多状态，如颜色、深度值、法线、纹理坐标等等，这些都可以通过三角形三个顶点相应状态插值得到。然后片元着色器接受上一阶段输入的片元，在此过程中完成一系列的渲染操作，如纹理采样等，这一步还会对每个片元执行一些其他操作，如[深度测试](https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/01%20Depth%20testing/)、[模板测试](https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/02%20Stencil%20testing/)、[混合](https://learnopengl-cn.github.io/04%20Advanced%20OpenGL/03%20Blending/)等等，最后输出每个片元的最终颜色值。最终会把所有的像素颜色信息整合在一起，输送给显示设备加以显示。这也就完成了整个图形渲染管线。

### 采样

采样的目的是为了判断像素中心是否在三角形内。

当然可以每次循环遍历整个屏幕空间的像素，但是一个三角形面可能只占屏幕很小的部分，这就会使效率很低，渲染结果变得很慢。其实只需要找到三角形三个顶点的包围盒，只遍历包围盒中的像素即可。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309181916491.png" style="width:50%;" />

对应代码：

``````cpp
    float minX = std::min({ pts[0].x, pts[1].x, pts[2].x });
    float maxX = std::max({ pts[0].x, pts[1].x, pts[2].x });
    float minY = std::min({ pts[0].y, pts[1].y, pts[2].y });
    float maxY = std::max({ pts[0].y, pts[1].y, pts[2].y });

    int AABBMinX = std::floor(minX);
    int AABBMaxX = std::ceil(maxX);
    int AABBMinY = std::floor(minY);
    int AABBMaxY = std::ceil(maxY);

    for(int x = AABBMinX; x <= AABBMaxX; ++x)
        for(int y = AABBMinY; y <= AABBMaxY; ++y)
            ......
``````

确定好包围盒后，接下来要判断包围盒里的每一个像素是否处在三角形内部：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309181933544.png" alt="叉乘判断一点是否在三角形内部" style="zoom:33%;" />

1. 可以使用叉乘的方法，$P_0P_1 × P_0Q$， $P_1P_2 × P_1Q$， $P_2P_1 × P_2Q$ 符号相同则在内部，否则在外部。

   ``````cpp
   bool insideTriangle(int x, int y, const Vector3f* _v)
   {   
       Vector3f Q;
       Q << x, y, 1;
   
       Vector3f AB = _v[1] - _v[0]; // P0 -> A point P1 -> B point
       Vector3f BC = _v[2] - _v[1]; // P2 -> C point
       Vector3f CA = _v[0] - _v[2]; 
   
       Vector3f AQ = Q - _v[0];
       Vector3f BQ = P - _v[1];
       Vector3f CQ = P - _v[2];
   
       Vector3f AB_AQ = AB.cross(AQ);
       Vector3f BC_BQ = BC.cross(BQ);
       Vector3f CA_CQ = CA.cross(CQ);
   
       if (AB_AQ.z() > 0 && BC_BQ.z() > 0 && CA_CQ.z() > 0) return true;
       else if (AB_AQ.z() < 0 && BC_BQ.z() < 0 && CA_CQ.z() < 0) return true;
   
       return false;
   }
   ``````
2. 利用重心坐标，重心坐标全都非负说明点 Q 在三角形内部：

   [重心坐标详细推导](https://zhuanlan.zhihu.com/p/149836719)

   ```cpp
   // 计算重心坐标
   Vector3f barycentric(const std::vector<Vector3f>& pts, const Vector3f& p) 
   {
       float xa = pts[0].x;
       float ya = pts[0].y;
       float xb = pts[1].x;
       float yb = pts[1].y;
       float xc = pts[2].x;
       float yc = pts[2].y;
       float x = p.x;
       float y = p.y;
   
       float gamma = ((ya - yb) * x + (xb - xa) * y + xa * yb - xb * ya) / ((ya - yb) * xc + (xb - xa) * yc + xa * yb - xb * ya);
       float beta = ((ya - yc) * x + (xc - xa) * y + xa * yc - xc * ya) / ((ya - yc) * xb + (xc - xa) * yb + xa * yc - xc * ya);
       float alpha = 1 - gamma - beta;
   
       return Vector3f(alpha, beta, gamma);
   }
   ```

   ```cpp
   void DrawTriangle(..., const Vector3f& color)
   {
       ......
       for(int x = AABBMinX; x <= AABBMaxX; ++x)
           for(int y = AABBMinY; y <= AABBMaxY; ++y)
           {
               Vector3f P(i, j);
               Vector3f baryCoord = barycentric(pts, P);
               // 像素不在三角形内
               if (baryCoord.x < 0 || baryCoord.y < 0 || baryCoord.z < 0)
                   continue;
               // 如果在，就绘制这个像素
               image.set(P.x, P.y, color);
           }
       ......
   }
   ```

至此，得到了所有的片元，接下来就要对所有的片元进行着色。

### 着色

我们之所以能看到物体，是因为人眼接收到了物体来的光。现实世界的光照是极其复杂的，而且会受到诸多因素的影响，这是有限的计算能力所无法模拟的。因此需要的光照模型进行简化，这样处理起来会更容易一些，而且看起来也差不多一样。

#### 冯氏光照模型(Phong Lighting Model)

冯氏光照模型的主要结构由 3 个分量组成：环境 (Ambient)、漫反射 (Diffuse) 和镜面 (Specular) 光照。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182031487.png" alt="冯氏光照模型" style="zoom:67%;" />

1. Ambient

   即使在黑暗的情况下，世界上通常也仍然有一些光亮（月亮、远处的光），所以物体几乎永远不会是完全黑暗的。为了模拟这个，通常会使用一个环境光照常量，它永远会给物体一些颜色。

   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182002627.png" alt="环境光" style="zoom: 67%;" />

   其中 $k_a$ 表示表面对环境光的反射率，$I_a$ 表示入射环境光的亮度。这个式子和 $l、v、n$ 都没关系，可以证实环境光颜色只是一个常数。

   ```glsl
   vec3 ka = (0.1, 0.1, 0.1);
   vec3 ambient = ka * lightColor;
   ```
2. Diffuse

   模拟光源对物体的方向性影响。它是冯氏光照模型中视觉上最显著的分量。物体的某一部分越是正对着光源，它就会越亮。并且漫反射光从一定角度入射之后会从入射点向四面八方反射，且每个不同方向反射的光的强度都相等。

   ##### Lambert’s cosine law

   Lambert 余弦定理： $l、n$ 的夹角决定光照强度，应该将光强乘上 $cos(θ) = l·n$ ：

   ![](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182014072.png)

   ##### 能量衰退定理


   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182018790.png" alt="能量衰退" style="zoom:67%;" />

   根据这两个理论，可以得到 Lambert 漫反射模型：

   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182022781.png" alt="漫反射模型" style="zoom: 67%;" />

   其中 $k_d$ 为漫反射系数，修改 $k_d$ 可以得到物体表面不同的颜色，*I* 为入射光强，*r* 为光源到入射点距离，$n、l$
   分别是法向量和入射方向，$max$ 是为了剔除夹角大于 90°的光（负数）。式子中没有出现 $v$ ，也证实了漫反射与观察方向无关。

   ```glsl
   vec3 norm = normalize(Normal); // 法线
   vec3 lightDir = normalize(lightPos - FragPos); // 入射光方向

   vec3 kd = (0.8, 0.8, 0.8);
   float diff = max(dot(norm, lightDir), 0.0);
   vec3 diffuse = kd * diff * lightColor;
   ```
3. Specular

   模拟有光泽物体上面出现的亮点。镜面光照的颜色相比于物体的颜色会更倾向于光的颜色。

   产生高光的条件：

   - 光滑的表面
   - 观察方向 $v$ 接近镜面反射 $R$ 方向

   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182036662.png" alt="镜面光" style="zoom:67%;" />

   判断 $v$ 和 $R$ 的距离：$cosθ = v ·R$。由此得到 Specular 项的颜色贡献：

   $$
   Ls=k_s(I/r^2)max(0, cos(θ))^p
   $$

   其中 $k_s$ 为镜面反射系数，*I* 为入射光强，*r* 为光源到入射点距离，$max$ 用来剔除大于90°的光（负数）。

   - 指数 *p* 的原因：防止反射光过大，离反射光越远就越不应该看见反射光，需要一个指数 *p* 加速衰减，如下图所示；

     ![Cosine Power Plots](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182046757.png)
   - 指数 *p* 的作用：控制高光的大小。

     ![不同 p 导致不同的高光大小](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182047354.png)

   ```glsl
   vec3 viewDir = normalize(viewPos - FragPos);
   vec3 reflectDir = reflect(-lightDir, norm); // reflect 函数要求第一个向量是从光源指向片段位置的向量
   
   vec3 ks = (0.5, 0.5, 0.5);
   float spec = pow(max(dot(viewDir, reflectDir), 0.0), 32);
   vec3 specular = ks * spec * lightColor;
   ```

#### 布林-冯光照模型（Blinn-Phong Lighting Model）

冯氏光照不仅对真实光照有很好的近似，而且性能也很高。但是它的镜面反射会在一些情况下出现问题，特别是物体反光度很低时，会导致大片（粗糙的）高光区域，下面这张图展示了当反光度为 1.0 时地板会出现的效果：

![](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182105602.png)

可以看到，在镜面高光区域的边缘出现了一道很明显的断层。出现这个问题的原因是观察向量和反射向量间的夹角不能大于 90 度。如果点积的结果为负数，镜面光分量会变为 0.0。你可能会觉得，当光线与视线夹角大于 90 度时你应该不会接收到任何光才对，所以这不是什么问题。

然而，这种想法仅仅只适用于漫反射分量。当考虑漫反射光的时候，如果法线和光源夹角大于 90 度，光源会处于被照表面的下方，这个时候光照的漫反射分量的确是为 0.0。但是，在考虑镜面高光时，我们测量的角度并不是光源与法线的夹角，而是视线与反射光线向量的夹角。

![](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182109079.png)

现在问题就应该很明显了。左图中是冯氏光照中的反射向量，其中 $\theta$ 角小于 90 度。而右图中，视线与反射方向之间的夹角明显大于 90 度，这种情况下镜面光分量会变为 0.0。这在大多数情况下都不是什么问题，因为观察方向离反射方向都非常远。然而，当物体的反光度非常小时，它产生的镜面高光半径足以让这些相反方向的光线对亮度产生足够大的影响。在这种情况下就不能忽略它们对镜面光分量的贡献了。

因此在冯氏着色模型上加以拓展，引入了 Blinn-Phong 着色模型。Blinn-Phong 模型与 Phong 模型非常相似，但是它对镜面光模型的处理上有一些不同，让我们能够解决之前提到的问题。Blinn-Phong 模型不再依赖于反射向量，而是采用了所谓的半程向量 (Halfway Vector)，即光线与视线夹角一半方向上的一个单位向量。当半程向量与法线向量越接近时，镜面光分量就越大。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182112162.png" alt="Blinn-Phong 高光项" style="zoom:67%;" />

```glsl
vec3 lightDir   = normalize(lightPos - FragPos);
vec3 viewDir    = normalize(viewPos - FragPos);
vec3 halfwayDir = normalize(lightDir + viewDir);

vec3 ks = (0.5, 0.5, 0.5);
float spec = pow(max(dot(normal, halfwayDir), 0.0), 32);
vec3 specular = ks * spec * lightColor;
```

最终计算结果：

![Phong 光照模型](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182058940.png)

```glsl
FragColor = ambient + diffuse + specular;
```

#### 着色频率

1. Flat Shading

   给每个三角面片里的所有像素都赋上相同颜色的着色方法叫做 Flat Shading。

   ```cpp
   Vec3f light_dir(0, 0, -1);
   for (int i = 0; i < model->nfaces(); i++)
   {
       ......
       normal.normalize(); // 三角形法线
       float intensity = normal * light_dir;
       if(intensity > 0)
           DrawTriangle(..., color);
       ......
   }
   ```

   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182128779.png" alt="Flat Shading" style="zoom: 33%;" />
2. Gouraud Shading

   在顶点着色器中实现冯氏光照模型被称作 Gouraud Shading。在顶点着色器中做光照的优势是，相比片段来说，顶点要少得多，因此会更高效，所以（开销大的）光照计算频率会更低。然而，顶点着色器中的最终颜色值是仅仅只是那个顶点的颜色值，片段的颜色值是由插值光照颜色所得来的。结果就是这种光照看起来不会非常真实，除非模型非常精细使用了大量顶点。

   <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182131607.png" alt="Gouraud Shading" style="zoom:150%;" />
3. Phong Shading

   在片元着色器中实现光照模型即为 Phong Shading。它根据插值定义逐像素法线，之后根据每个像素法线求出该像素的颜色。

三种着色频率对比

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309182138717.png" alt="三种着色频率对比" style="zoom:67%;" />

### 纹理

为了让渲染的结果更具真实性可以为每个顶点单独设置颜色，但这无疑也会造成很大的开销，所以就引入了纹理，可以用来添加物体的细节。

为了能够把纹理映射(Map)到三角形图元上，就需要指定三角形的每个顶点各自对应纹理的哪个部分，想象一个地球仪的例子：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201251046.png" alt="映射" style="zoom:70%;" />

倘若拥有从三维世界坐标空间到二维纹理空间的一个映射关系，那么只需要将每个点的颜色信息即反射系数（$k_a$ $k_d$ $k_s$）存储在二维的纹理上，每次利用光照模型进行计算的时候根据映射关系就能查到这个点的反射系数是多少，所有点计算完之后，结果就像最左边的屏幕空间中，整个纹理被贴在了模型之上。

#### 纹理坐标

纹理坐标在 x 和 y 轴上，范围为 0 到 1 之间（2D纹理图像）。使用纹理坐标获取纹理颜色叫做采样。纹理坐标起始于 (0, 0)，也就是纹理图片的左下角，终止于 (1, 1)，即纹理图片的右上角。

![纹理坐标](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201250195.png)

伪代码：

```cpp
void DrawTriangle(...)
{
    ......
    for(int x = AABBMinX; x <= AABBMaxX; ++x)
        for(int y = AABBMinY; y <= AABBMaxY; ++y)
        {
            Vector3f P(i, j);
            Vector2f pUV;
            Vector3f baryCoord = barycentric(pts, P);
            // 像素不在三角形内
            if (baryCoord.x < 0 || baryCoord.y < 0 || baryCoord.z < 0)
                continue;

            // 通过重心坐标插值得到该像素的 uv 坐标
            pUV = baryCoord.x * uv[0] + baryCoord.y * uv[1] + baryCoord.z * uv[2];
            Vector3f color = obj.sample(pUV);
            image.set(P.x, P.y, color);           
        }
    ......
}
```

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201249061.png" alt="纹理映射" style="zoom:67%;" />

### 深度测试

如果需要绘制多个物体到屏幕上时，这些物体之间存在遮挡关系，那么怎样才能在渲染的时候表现出正确的遮挡关系呢？

有种叫做 Painter's Algorithm 的算法，就像画家在画油画一样：给想要同时绘制的物体按照远近距离进行排序，在绘制的时候，按照从远到近的顺序进行绘制，因为离得比较近的物体后绘制，所以会覆盖之前比较远的物体绘制的结果，这样就能渲染出正确的遮挡关系了。但是因为涉及到排序这种方法的效率不高，而且很多情况下物体间的遮挡关系很难通过排序确定下来，比如：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201259715.png" alt="遮挡关系" style="zoom:50%;" />

所以就出现了 `z-buffer` 算法。 `z-buffer` 算法要求在绘制场景时生成两张图：

1. 颜色图（Color Buffer），也叫帧缓冲区（Frame Buffer）：存放每个像素的颜色值。
2. 深度图（Depth Buffer、Z-Buffer），也叫深度缓存：存放每个像素当前离摄像机最近的深度值，离摄像机越近深度越小，越远深度越大，越近深度越小深度值越趋向 0 也就越黑，越远深度越大深度值越趋向 1 也就越白.

![深度缓存示例](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201305142.png)

 `z-buffer` 算法需要为每个像素点维持一个深度数组记为 `z-buffer` ，其每个位置初始值置为无穷大（即离摄像机无穷远）。随后遍历每个三角形面上的每一个像素点 $(x, y)$，如果该像素点的深度值 z，小于 zbuffer[x, y] 中的值，则更新zbuffer[x, y] 值为该点深度值z，并同时更新该像素点 $(x, y)$ 的颜色为该三角形面上的该点的颜色。

相应代码：

```cpp
// 初始化 zBuffer
std::vector<float> zBuffer(WIDTH * HEIGHT, -std::numeric_limits<float>::max());

void DrawTriangle(...)
{
    ......
    for(int x = AABBMinX; x <= AABBMaxX; ++x)
        for(int y = AABBMinY; y <= AABBMaxY; ++y)
        {
            Vector3f P(i, j);
            Vector2f pUV;
            Vector3f baryCoord = barycentric(pts, P);
            // 像素不在三角形内，终止此次循环
            if (baryCoord.x < 0 || baryCoord.y < 0 || baryCoord.z < 0)
                continue;
            // 通过重心坐标插值得到该像素的深度值以及 uv 坐标
            float zInterpolation = baryCoord.x * pts[0].z + baryCoord.y * pts[1].z + baryCoord.z * pts[2].z;
            pUV = baryCoord.x * uv[0] + baryCoord.y * uv[1] + baryCoord.z * uv[2];

            // 执行深度测试
            if (zInterpolation < zBuffer[x, y])
            {
                zBuffer[x, y] = zInterpolation; // 更新 zBuffer
                Vector3f color = obj.sample(pUV);
                image.set(P.x, P.y, color); // 着色
            }           
        }
    ......
}
```

图左为未执行深度测试，图右为执行了深度测试：

<center style="display: flex;">
    <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201316284.png" alt="未执行深度测试" style="zoom:50%;" />
    <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309201317934.png" alt="执行了深度测试" style="zoom:50%;" />
</center>

至此，光栅化的主要流程基本完成。

