---
    slug: shadow
    title: 阴影
    date: 2023-09-26
    authors: Kaesar
    tags: [CG, Rendering, Rasterization, Shadow, Shadow Map, Depth, PCSS, PCF, VSSM]
    keywords: [阴影, Shadow Map, PCF, PCSS, VSMM]
---
<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261857967.png" alt="PCSS 软阴影效果图" style="zoom: 70%;" />

<br/>

阴影是光线被阻挡的结果；当一个光源的光线由于其他物体的阻挡不能够达到一个物体的表面的时候，那么这个物体就会处在阴影中。阴影能够使场景看起来真实得多，并且可以让观察者获得物体之间的空间位置关系。场景和物体的深度感因此能够得到极大提升。

### 阴影映射（Shadow Mapping）

#### 原理

Shadow Mapping 的理论很简单，分为两个渲染阶段：

1. 首先以光源的位置为视角渲染场景，得到所有像素的深度值，由此形成一张深度贴图；
2. 再以摄像机的位置为视角渲染场景，判断像素是否在阴影中。具体判断方法为：**将该像素在摄像机的坐标空间转换到以光源为视角的坐标空间中，比较该像素的深度值（z 分量）与深度贴图中存储的该像素的深度值，如果大于则位于阴影中，小于则不在阴影中。**

![阴影映射](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261856338.png)

从上图可以看到点 P 被遮挡，点 Q 没被遮挡。

在微积分中，有一个重要的约等式：

$$
\int_{\Omega}{f(x)g(x)dx} ≈ \frac{\int_{\Omega}{f(x)dx}}{\int_{\Omega}{dx}} \times \int_{\Omega}{g(x)dx}
$$

即乘积的积分可以拆成积分的乘积，式子右边分母是为了做归一化防止能量爆炸。

来看考虑阴影的渲染方程：

$$
L_0(p, \omega_0) = L_e(p, \omega_0) + \int_{\Omega^+}{L_i(p, \omega_i)f_r(p, \omega_0, \omega_i)cos(\theta)V(p, \omega_i)d\omega_i}
$$

积分中比原始的反射方程多出了 $V(p, \omega_i)$ 可见性（visibility）项，当着色点位于阴影中时该点不可见，其值为 0，反之则为 1。根据上述约等式可将渲染方程变形：

$$
L_0(p, \omega_0) ≈ L_e(p, \omega_0) + \frac{\int_{\Omega^+}{V(p, \omega_i)d\omega_i}}{\int_{\Omega^+}d\omega_i}\int_{\Omega^+}{L_i(p, \omega_i)f_r(p, \omega_0, \omega_i)cos(\theta)d\omega_i}
$$

观察发现反射方程右部分为颜色，左部分为可见性。这恰好符合 Shadow Mapping 的思想，即先着色，再判断是否可见。

#### 伪代码

第一次渲染只需要输出深度数据，而不需要着色。以下是我自己的渲染引擎 [Kaesar](https://github.com/qzlu-cyber/Kaesar) 中相关的实现代码

```cpp
// 传递光源的变换矩阵
s_Data.shadowUniformBuffer = UniformBuffer::Create(sizeof(glm::mat4), 4); // 将和光源空间变换有关的数据绑定在 4 号绑定点
s_Data.lightProjection = glm::perspective(45.0f, 1.0f, s_Data.lightNear, s_Data.lightFar);
s_Data.lightView = glm::lookAt(-(glm::normalize(light->GetDirection()) * s_Data.lightFar / 		4.0f), glm::vec3(0.0f), glm::vec3(0.0f, 1.0f, 0.0f));
s_Data.shadowBuffer.lightViewProjection = s_Data.lightProjection * s_Data.lightView;
s_Data.shadowUniformBuffer->SetData(&s_Data.shadowBuffer, sizeof(glm::mat4));

// 渲染深度贴图
s_Data.shadowPass->BindTargetFrameBuffer(); // 阴影帧缓冲
RenderCommand::SetState(RenderState::DEPTH_TEST, true);
RenderCommand::SetClearColor(s_Data.shadowPass->GetSpecification().TargetFrameBuffer-			>GetSpecification().ClearColor);
RenderCommand::Clear();
s_Data.depthShader->Bind();
for (auto& entity : view) // 遍历所有要渲染的物体
{
    auto& transformComponent = view.get<TransformComponent>(entity);
    auto& meshComponent = view.get<MeshComponent>(entity);

    if (!meshComponent.path.empty())
    {
        s_Data.depthShader->SetMat4("transform.u_Transform", transformComponent.GetTransform()); // 传递物体的 MVP 变换矩阵
        SceneRenderer::RenderEntity(entity, meshComponent, s_Data.depthShader); // 渲染指令
    }
}
s_Data.depthShader->Unbind();
s_Data.shadowPass->UnbindTargetFrameBuffer();
```

```glsl
// depthShader.glsl 负责把顶点变换到光空间
// vertexShader
layout(binding = 4) uniform Shadow
{
    mat4 u_LightViewProjection;
} shadow;

layout(push_constant) uniform Transform
{
    mat4 u_Transform;
} transform;

void main()
{
    gl_Position = shadow.u_LightViewProjection * transform.u_Transform * vec4(a_Position, 1.0);
}

// 不需要着色，所以 fragmentShader不用做任何事
```

第二次渲染时要保证在同一坐标空间下比较深度值，然后判断是否在阴影中。

```glsl
// renderShader.glsl
// vertexShader
vec4 FragPosLightSpace = shadow.u_LightViewProjection * vec4(fragPos, 1.0);

// fragmentShader
float shadowMap(sampler2D shadowMap, vec4 shadowCoord) 
{
    float shadowDepth = unpack(texture2D(uShadowMap, shadowCoord.xy));
    if (shadowCoord.z - (shadowDepth + calcBias()) > EPS) 
        return 0.0;

    return 1.0;
}

void main()
{
    // 将灯光视角下的顶点裁剪 NDC 坐标 [-1, 1] 映射到线性深度 [0, 1]
    vec3 shadowCoord = 0.5 * FragPosLightSpace.xyz / FragPosLightSpace.w + vec3(0.5);
    // 取得当前片段在光源视角下的深度
    float currentDepth = projCoords.z;
    // 取得最近点的深度
    float closestDepth = texture(shadowMap, shadowCoord.xy).r;
    // 检查当前片段是否在阴影中
    float shadow = currentDepth > closestDepth  ? 1.0 : 0.0;
  
    FragColor = vec4(color * (1 - shadow), 1.0);
}
```

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261855849.png" alt="Shadow Mapping 效果" style="zoom:40%;" />

#### 自遮挡问题

使用 Shadow Mapping 容易出现自遮挡的问题，出现的原因主要是由阴影图的分辨率，每个阴影图的纹素对应场景中的一块区域（而非点对点）。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261853401.png" alt="Shadow Mapping 自遮挡" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261901918.png" alt="阴影瑕疵" style="zoom:80%;" />

<br/>

不难推断，光线越接近垂直照射时自遮挡程度越轻，越接近水平照射时程度越重。简单的一种解决方案是容忍一段区间的遮挡物，即将阴影图中的深度值偏移一段。这一段距离被称为 *bias*：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261854423.png" alt="bias 偏移" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261903934.png" alt="阴影瑕疵消失" style="zoom: 80%;" />

<br/>

可以简单地将 *bias* 设置为一个常数，通常 0.005 就能拥有比较好的效果。*bias* 过大又会引发 `peter-panning` 问题，导致阴影丢失（下图 Marry 的脚的阴影丢失了），原因是由于 *bias* 过大从而忽略了原本在阴影里的点。

![彼得潘现象](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309261915681.png)

也可以设置动态 *bias*，其值和法线与光照方向夹角有关  `float bias = max(0.01 * (1.0 - dot(N, L)), 0.005)` 。具体推导：[自适应Shadow Bias算法](https://zhuanlan.zhihu.com/p/370951892)

### Percentage Closer Filtering (PCF)

在上面几张使用 Shadow Mapping 的渲染图中不难看出，阴影走样严重，PCF 可以用来反走样，类似光栅化抗锯齿中的 MSAA 方法。

#### 原理

Shadow Mapping 产生走样的原因：在第一趟渲染产生了深度贴图后（如下图），第二趟渲染要对 *p* 点进行着色，就要先判断它是否在阴影中，由于只会得到两种结果在或者不在，就使得阴影的产生完全没有过渡性，就发生了走样现象。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281522551.png" alt="深度图" style="zoom:70%;" />

PCF 的做法是：在第二趟渲染比较两次渲染的深度值时不再是单纯得到一个二元结果，不止让 *p* 点和它对应的深度图的纹素（texel）中的 z 值比较，而是选择一个点 *p* 映射在阴影图中的 texel 为中心的 $n \times n$ 的 filtering（核），使用点 *p* 的深度值 *d*(*p*) 分别和 filtering 中每个纹素采样结果 *s(p)* 进行比较，最后得到 $n^2$ 个二元比较结果，相加之后进行平均，最终得到这个 *p* 点的阴影，而这个结果不再是非黑即白的二元值，自然也就减轻了走样的现象。

例如对于上图 *p* 点，先得到其深度值 *d*(*p*)，再在阴影图中对以 *p* 点为中心的 3x3 的核进行采样得到 *s(p)* ，然后将

*d*(*p*) 和 *s*(*p*) 作比较，假设得到 3x3 个比较结果，

$$
\begin{pmatrix}
   0 & 0 & 1 \\
   1 & 1 & 0 \\
   0 & 1 & 1 \\
   \end{pmatrix}
$$

最后对这个 3x3 的比较结果进行平均，得到 *p* 点的阴影项 *visibility* = 0.667.

#### 伪代码

```glsl
// 取得当前片段在光源视角下的深度
float currentDepth = projCoords.z;
float shadow = 0.0;
// textureSize 返回一个给定采样器纹理的 0 级 mipmap 的 vec2 类型的宽和高
// 用 1 除以它返回一个单独纹理像素的大小
vec2 texelSize = 1.0 / textureSize(shadowMap, 0);

for(int x = -1; x <= 1; ++x)
{
    for(int y = -1; y <= 1; ++y)
    {
        float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r; 
        if (currentDepth > (bias + pcfDepth))
            shadow += 1.0;    
    }  
}
shadow /= 9.0;
```

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281552587.png" alt="PCF 最终效果" style="zoom:60%;" />

<br/>

可以观察到，走样问题减轻了许多。而且，filtering 的尺寸决定了阴影的软硬程度。filtering 的尺寸越大，得到的阴影越软，尺寸越小，得到的阴影越硬，因此 PCF 后来也被用到软阴影的制作中。

### Percentage Closer Soft Shadows (PCSS)

在现实中，阴影的软硬程度并不是一成不变的，例如下面这张图，越靠近遮挡物阴影越重（笔尖部分），越远离遮挡物阴影越软（笔杆部分）：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281625054.png" alt="软硬阴影" style="zoom:75%;" />

<br/>

也即是说阴影的软硬程度与遮挡物的距离有关。而 PCSS 就是研究这种阴影软硬程度与遮挡物距离关系的物理模型。

#### 原理

前面提到，在 PCF 中，filtering 的大小决定了阴影的软硬程度。所以 PCSS 的核心就是根据遮挡物距离动态的选择一个适应性的 filtering 尺寸去做 PCF。 灯光、遮挡物、阴影接受物关系如下图：

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281630069.png" alt="PCSS 原理图" style="zoom:75%;" />

<br/>

$W_{Penumbra}$ 即为 filtering 的尺寸，根据相似三角形可以求出：

$$
W_{Penumbra} = (d_{Receiver} - d_{Blocker}) \times W_{Light} \div d_{Blocker}
$$

等式中，$d_{Receiver}$ 和 $W_{Light}$ 已知，还需要知道 $d_{Blocker}$，它代表光源到遮挡物的垂直距离。PCSS 取 *Blocker* 范围内的平均垂直距离作为 $d_{Blocker}$。也就是说，对于一个着色点，要看在一定范围内，有多少能够遮挡住它，取它们深度的平均值作为 $d_{Blocker}$。

问题又来了，“一定范围内”要取多大的范围呢？它取决于光源大小和接受物到光源的距离。具体来说，从着色点连向光源，找到它覆盖的阴影贴图区域，然后在这个区域内寻找 *Blocker*。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281640423.png" style="zoom:67%;" />

<br/>

所以，PCSS 的整个流程可以概括为 3 步：

1. Blocker Search：找到一个范围，在这个范围内寻找 *Blocker*，再计算所有 *Blocker* 的平均深度得到 $d_{Blocker}$；
2. Penumbra Estimation：用 $d_{Blocker}$ 求解出 filtering 尺寸 $W_{Penumbra}$；
3. PCF：利用 filtering 尺寸，进行 PCF 操作。

#### 伪代码

```glsl
float SearchWidth(float uvLightSize, float receiverDistance)
{
    return uvLightSize * (receiverDistance - pc.near) / receiverDistance;
}

float FindBlockerDistance(vec3 shadowCoords, sampler2D shadowMap, float uvLightSize, float bias)
{
    int blockers = 0; // 遮挡者的数目
    float blockerDepth = 0.0; // 总的遮挡深度
    float searchWidth = SearchWidth(uvLightSize, shadowCoords.z);

    for (int i = 0; i < pc.numBlockerSearchSamples; i++)
    {
        vec2 uvOffset = RandomDirection(distribution0, i / float(pc.numBlockerSearchSamples)) * searchWidth; // 通过随机采样进行偏移
        float shadowDepth = texture(shadowMap, shadowCoords.xy + uvOffset).r;
        if (shadowCoords.z > (shadowDepth + bias))
        {
            blockers++;
            blockerDepth += shadowDepth;
        }
    }

    if (blockers > 0)
        return blockerDepth / blockers; // 返回平均深度

    return -1.0; // 无遮挡
}

float PCF(vec3 shadowCoords, sampler2D shadowMap, float uvRadius, float bias)
{
    float blocker;
    float radius = uvRadius;

    float sum = 0;
    for (int i = 0; i < pc.numPCFSamples; i++)
    {
        vec2 uvOffset = RandomDirection(distribution1, i / float(pc.numPCFSamples)) * uvRadius;
        float shadowDepth = texture(shadowMap, shadowCoords.xy + uvOffest).r;
        if (shadowCoords.z - (shadowDepth + bias) > 0)
            sum += 1.0;
    }

    return sum / pc.numPCFSamples;
}

float PCSS_DirectionalLight(vec3 shadowCoords, sampler2D shadowMap, float uvLightSize, float bias)
{
    // Blocker Search
    float avgBlockerDepth = FindBlockerDistance(shadowCoords, shadowMap, uvLightSize, bias);

    // 没有被阻挡无阴影
     if (avgBlockerDepth == -1.0)
         return 0.0;

    // Penumbra size
    float penumbraWidth = (shadowCoords.z - avgBlockerDepth) * float(pc.size) / avgBlockerDepth;

    // PCF
    return PCF(shadowCoords, shadowMap, penumbraWidth, bias);
}
```

下面左图使用了 PCSS，右图只用了 PCF：

<center style="display: flex;">
    <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281659090.png" alt="PCSS 效果" style="zoom:40%;" />
    <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281700288.png" alt="PCF 效果" style="zoom:40%;" />
</center>

<br/>

但是 PCSS 由于需要对每个着色点都要做以上三部，尤其是 1 和 3 步，严重影响了其速度，导致 PCSS 运行较慢。有两种解决方案。，第一种方案是在 Step1 中对稀疏的范围进行 *Blocker* 判断，且在 Step3 中对 filtering 中的阴影贴图进行稀疏采样，但这样会带来噪声的问题，解决方法是在图像空间进行降噪。 第二种方案是 VSSM。

### Variance Soft Shadow Mapping (VSSM)

VSSM 是解决 PCSS 中 Step1 和 Step3 过慢的一种方案。

首先讨论 Step3：回想 PCF 的计算过程，可以转化成求 ${d_p}$ 在所有的 $s_p$ 中排第几。例如上面 PCF 的例子，结果中有 5 个深度比 *p* 浅的，也即是 *p* 排第六，则 $d_p$ 占比为 $\frac{6}{9} = 0.667$ 即为 *p* 点的 *visibility* 项。

只要给定给定一张由 $s_i$ 组成的直方图，那么就可以确定 $d_p$ 在 $s_i$ 中的排名。正态分布由期望和方差决定，可以把直方图近似为正态分布简化计算。问题就变成了期望和方差如何获取。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281724380.png" alt="直方图" style="zoom:60%;" />

均值可以通过阴影贴图求得，方差比较难算，但概率论中有一个非常有用的公式：

$$
Var(x) = E(x^2) - E^2(x)
$$

即方差等于平方的期望和期望的平方的差值。这样就只需再拿一张纹理来存储像素深度的平方用来简化方差的计算即可。

在概率论中，概率密度函数（PDF）为连续型随机变量的概率密度函数，概率质量函数（PMF）为离散型随机变量的概率密度函数，累积分布函数（CDF）为概率密度函数的积分。即 $CDF = PDF + PMF$。反映在正态分布中，CDF 对应函数值与横轴围成的面积。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281732406.png" alt="CDF PDF" style="zoom:67%;" />

也就是说，对于一个值 *x*，只需要求出 $CDF(x)$，就可以得到百分之多少的值是小于它的，也即得到了它的排名。然而， CDF 一般很难计算，不过，可以用切比雪夫不等式去近似计算：

$$
P(x > t) \leq \frac{\sigma^2}{\sigma^2 + (t - \mu)^2}
$$

其中，$\sigma$ 为期望，$\mu$ 为方差。则 $CDF(x) = 1 - P(x > t)$。至此就可以近似得到：

$$
Visibility(p) ≈ PCF = 1 - P(x > t) ≈ 1 - \frac{\sigma^2}{\sigma^2 + (t - \mu)^2}
$$

需要注意，切比雪夫不等式规定：*t* 必须在均值的右边。*t* 必须在均值的左边时，计算结果可能会不准确。

再来看 Step1：求平均遮挡物深度是多少？假设物体深度为 7，则下图中蓝色区域为遮挡物深度，红色区域为被遮挡物深度。只需要对蓝色区域的值进行一个平均，而非所有区域的值。

<img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202309281747718.png" alt="Blocker Depth" style="zoom:67%;" />

<br/>

如果一个着色点的深度为 *t*，则 $z < t$ 的为遮挡物，$z > t$ 的为非遮挡物。设一个区域内共 *N* 个物体，要求的 $N_1$ 个遮挡物的平均深度为 $z_{occ}$， $N_2$ 非遮挡物平均深度为 $z_{unocc}$，则整个区域的平均深度为：

$$
z_{avg} = \frac{N_1}{N} z_{occ} + \frac{N_2}{N} z_{unocc}
$$

将其对应到切比雪夫不等式上做近似：

$$
\frac{N_1}{N} = 1 - P(x > t) \\ \\
\frac{N_2}{N} = P(x > t)
$$

但是，此时 $z_{unocc}$ 还未知，做一个大胆假设，就认为  $z_{unocc} = t$，即所有非遮挡物的深度全都和着色点深度相同。这样，就可以求得 $z_{occ}$，PCSS 算法也就加速完成。
