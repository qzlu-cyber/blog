---
    slug: cgbagu
    title: 图形学面试八股
    date: 2024-03-14
    authors: Kaesar
    tags: [CG, OpenGL, PBR]
    keywords: [CG, OpenGL, PBR]
---

#### 图形学

##### OpenGL

1. **什么是 GLFW？**

   答：在我们画出出色的效果之前，首先要做的就是创建一个OpenGL上下文(Context)和一个用于显示的窗口。然而，这些操作在每个系统上都是不一样的，OpenGL有意将这些操作抽象(Abstract)出去。这意味着我们不得不自己处理创建窗口，定义OpenGL上下文以及处理用户输入。

   GLFW是配合 OpenGL 使用的轻量级工具程序库，缩写自 Graphics Library Framework（图形库框架）。GLFW 的主要功能是创建并管理窗口和 OpenGL 上下文，同时还提供了处理手柄、键盘、鼠标输入的功能。

2. **什么是 GLAD？**

   答：GLAD是用来管理OpenGL的函数指针的。因为OpenGL只是一个标准/规范，具体的实现是由驱动开发商针对特定显卡实现的。由于OpenGL驱动版本众多，它大多数函数的位置都无法在编译时确定下来，需要在运行时查询。所以任务就落在了开发者身上，开发者需要在运行时获取函数地址并将其保存在一个函数指针中供以后使用。

   **在包含GLFW的头文件之前包含了GLAD的头文件。GLAD的头文件包含了正确的OpenGL头文件（例如`GL/gl.h`），所以需要在其它依赖于OpenGL的头文件之前包含GLAD。**

3. **VBO**

   答：使用一个顶点缓冲对象将顶点数据初始化至缓冲中，建立了一个顶点和一个片段着色器，并告诉了OpenGL如何把顶点数据链接到顶点着色器的顶点属性上。在OpenGL中绘制一个物体，代码会像是这样：

   ```cpp
   // 0. 复制顶点数组到缓冲中供OpenGL使用
   glBindBuffer(GL_ARRAY_BUFFER, VBO);
   glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
   // 1. 设置顶点属性指针
   glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
   glEnableVertexAttribArray(0);
   // 2. 当我们渲染一个物体时要使用着色器程序
   glUseProgram(shaderProgram);
   // 3. 绘制物体
   someOpenGLFunctionThatDrawsOurTriangle();
   ```

   每当我们绘制一个物体的时候都必须重复这一过程。这看起来可能不多，但是如果有超过5个顶点属性，上百个不同物体呢（这其实并不罕见）。绑定正确的缓冲对象，为每个物体配置所有顶点属性很快就变成一件麻烦事。有没有一些方法可以使我们把所有这些状态配置储存在一个对象中，并且可以通过绑定这个对象来恢复状态呢？**VAO**！

4. **VAO**

   答：任何随后的顶点属性调用都会储存在这个VAO中。这样的好处就是，当配置顶点属性指针时，你只需要将那些调用执行一次，之后再绘制物体的时候只需要绑定相应的VAO就行了。这使在不同顶点数据和属性配置之间切换变得非常简单，只需要绑定不同的VAO就行了。刚刚设置的所有状态都将存储在VAO中。

   ```cpp
   unsigned int VAO;
   glGenVertexArrays(1, &VAO);
   
   // ..:: 初始化代码（只运行一次 (除非你的物体频繁改变)） :: ..
   // 1. 绑定VAO
   glBindVertexArray(VAO);
   // 2. 把顶点数组复制到缓冲中供OpenGL使用
   glBindBuffer(GL_ARRAY_BUFFER, VBO);
   glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
   // 3. 设置顶点属性指针
   glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
   glEnableVertexAttribArray(0);
   
   [...]
   
   // ..:: 绘制代码（渲染循环中） :: ..
   // 4. 绘制物体
   glUseProgram(shaderProgram);
   glBindVertexArray(VAO);
   someOpenGLFunctionThatDrawsOurTriangle();
   ```

5. **EBO**

   答：一个矩形只有4个而不是6个顶点，这样就产生50%的额外开销。当我们有包括上千个三角形的模型之后这个问题会更糟糕，这会产生一大堆浪费。更好的解决方案是只储存不同的顶点，并设定绘制这些顶点的顺序。这样子我们只要储存4个顶点就能绘制矩形了，之后只要指定绘制的顺序就行了。**EBO是一个缓冲区，就像一个顶点缓冲区对象一样，它存储 OpenGL 用来决定要绘制哪些顶点的索引。**

   ```cpp
   // ..:: 初始化代码 :: ..
   // 1. 绑定顶点数组对象
   glBindVertexArray(VAO);
   // 2. 把我们的顶点数组复制到一个顶点缓冲中，供OpenGL使用
   glBindBuffer(GL_ARRAY_BUFFER, VBO);
   glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);
   // 3. 复制我们的索引数组到一个索引缓冲中，供OpenGL使用
   glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);
   glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);
   // 4. 设定顶点属性指针
   glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);
   glEnableVertexAttribArray(0);
   
   [...]
   
   // ..:: 绘制代码（渲染循环中） :: ..
   glUseProgram(shaderProgram);
   glBindVertexArray(VAO);
   glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0);
   glBindVertexArray(0);
   ```

6. **Uniform**

   答：Uniform是一种从CPU中的应用向GPU中的着色器发送数据的方式，但uniform和顶点属性有些不同。首先，uniform是全局的。全局意味着uniform变量必须在每个着色器程序对象中都是独一无二的，而且它可以被着色器程序的任意着色器在任意阶段访问。第二，无论你把uniform值设置成什么，uniform会一直保存它们的数据，直到它们被重置或更新。

   ```cpp
   float timeValue = glfwGetTime();
   float greenValue = (sin(timeValue) / 2.0f) + 0.5f;
   int vertexColorLocation = glGetUniformLocation(shaderProgram, "ourColor");
   glUseProgram(shaderProgram);
   glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f);
   ```

7. **纹理贴图**

   - **纹理技术的基本原理**，简单的理解就是将一张二维图像，按照一定的映射关系，将每个像素贴合到物体表面的对应位置。纹理技术可以增加物体表面的细节。

   - **纹理环绕和纹理过滤(采样)**

     1. 环绕方式：设置纹理坐标采样超出范围时，采取什么行为(重复/镜像/插值到边缘等)
     2. 过滤方式：决定怎样将纹理像素映射到纹理坐标（怎样对纹理像素采样），分为临近过滤和线性过滤(采样)

   - **mipmap的概念，如何实现**

     提出背景：在一个场景内有很多物体，有的远有的近。远处的物体只占很少的片段（假设每个物体都有各自的纹理，且分辨率都很高的话），此时从高分辨率纹理中为这些片段获取正确的颜色值就很困难，因为它需要对一个跨过纹理很大部分的片段只拾取一个纹理颜色（因为一个很小的物体，一个像素映射到纹理上会占据很大一块，包含了很多个纹理像素，不好采样）。在小物体上这会产生不真实的感觉，而且对它们使用高分辨率纹理也会存在浪费内存的问题。因此引出了多级渐远纹理(mipmap)技术。

     **原理：** 将纹理划分为不同大小分辨率的纹理图集，每次缩小1/2划分，根据物体的大小，来对不同级别的纹理进行采样。对远处的物体，采用低分辨率的纹理，对于近处的物体，采用高分辨率的纹理。

     一个常见的错误是，将放大过滤的选项设置为多级渐远纹理过滤选项之一。这样没有任何效果，因为多级渐远纹理主要是使用在纹理被缩小的情况下的：纹理放大不会使用多级渐远纹理，在OpenGL中为放大过滤设置多级渐远纹理的选项会产生一个GL_INVALID_ENUM错误代码。

   - **如何确定使用哪一层的Mipmap？**

     计算一个像素与其所覆盖的纹理区域的面积比例（取x,y方向上的最大缩放值），由此选定mipmap层

     `float lod = 0.5 * log2(max(dot(px, px), dot(py, py)));` 

     `px`和`py`分别是沿x轴和y轴的纹理坐标变化量（通过`dFdx(uv)`和`dFdy(uv)`计算得出）。`dot(px, px)`和`dot(py, py)`计算的是这些变化量的长度的平方，用于估计纹理变形的程度。然后，取这两个值中的最大值，通过`log2`函数计算出应选择的Mipmap级别。当纹理被映射到较远或较小的表面时，相邻像素间的`uv`跨度会增加，意味着需要使用更低分辨率的纹理级别来减少走样和提高渲染效率。相反，当纹理映射到较近或较大的表面时，`uv`跨度较小，这时候使用更高分辨率的纹理级别可以获得更清晰的图像。

8. **FBO**

   用于写入颜色值的颜色缓冲、用于写入深度信息的深度缓冲和允许我们根据一些条件丢弃特定片段的模板缓冲。这些缓冲结合起来叫做帧缓冲(Framebuffer)，它被储存在内存中。OpenGL允许我们定义我们自己的帧缓冲，也就是说我们能够定义我们自己的颜色缓冲，甚至是深度缓冲和模板缓冲。

   一个完整的帧缓冲需要满足以下的条件：

   - 附加至少一个缓冲（颜色、深度或模板缓冲）。
   - 至少有一个颜色附件(Attachment)。
   - 所有的附件都必须是完整的（保留了内存）。
   - 每个缓冲都应该有相同的样本数。

   要想绘制场景到一个纹理上，需要采取以下的步骤：

   1. 将新的帧缓冲绑定为激活的帧缓冲，和往常一样渲染场景
   2. 绑定默认的帧缓冲
   3. 绘制一个横跨整个屏幕的四边形，将帧缓冲的颜色缓冲作为它的纹理。

   ```cpp
   // 第一处理阶段(Pass)
   glBindFramebuffer(GL_FRAMEBUFFER, framebuffer);
   glClearColor(0.1f, 0.1f, 0.1f, 1.0f);
   glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); // 我们现在不使用模板缓冲
   glEnable(GL_DEPTH_TEST);
   DrawScene();    
   
   // 第二处理阶段
   glBindFramebuffer(GL_FRAMEBUFFER, 0); // 返回默认
   glClearColor(1.0f, 1.0f, 1.0f, 1.0f); 
   glClear(GL_COLOR_BUFFER_BIT);
   
   screenShader.use();  
   glBindVertexArray(quadVAO);
   glDisable(GL_DEPTH_TEST);
   glBindTexture(GL_TEXTURE_2D, textureColorbuffer);
   glDrawArrays(GL_TRIANGLES, 0, 6);
   ```

9. **RBO**

   和纹理图像一样，渲染缓冲对象(RBO)是一个真正的缓冲，即一系列的字节、整数、像素等。渲染缓冲对象附加的好处是，它会将数据储存为OpenGL原生的渲染格式，它是为离屏渲染到帧缓冲优化过的。

   渲染缓冲对象直接将所有的渲染数据储存到它的缓冲中，不会做任何针对纹理格式的转换，让它变为一个更快的可写储存介质。然而，渲染缓冲对象通常都是只写的，所以你不能读取它们（比如使用纹理访问）。当然你仍然还是能够使用glReadPixels来读取它，这会从当前绑定的帧缓冲，而不是附件本身，中返回特定区域的像素。

   因为它的数据已经是原生的格式了，当写入或者复制它的数据到其它缓冲中时是非常快的。所以，交换缓冲这样的操作在使用渲染缓冲对象时会非常快。我们在每个渲染迭代最后使用的glfwSwapBuffers，也可以通过渲染缓冲对象实现：只需要写入一个渲染缓冲图像，并在最后交换到另外一个渲染缓冲就可以了。渲染缓冲对象对这种操作非常完美。

10. **立方体贴图**

    立方体贴图有一个非常有用的特性，它可以通过一个方向向量来进行索引/采样。用立方体贴图可以制作天空盒。用于贴图3D立方体的立方体贴图可以使用立方体的位置作为纹理坐标来采样。当立方体处于原点(0, 0, 0)时，它的每一个位置向量都是从原点出发的方向向量。这个方向向量正是获取立方体上特定位置的纹理值所需要的。正是因为这个，我们只需要提供位置向量而不用纹理坐标了。

11. **几何着色器**

    在顶点和片段着色器之间有一个可选的几何着色器(Geometry Shader)，几何着色器的输入是一个图元（如点或三角形）的一组顶点。几何着色器可以在顶点发送到下一着色器阶段之前对它们随意变换。然而，几何着色器最有趣的地方在于，它能够将（这一组）顶点变换为完全不同的图元，并且还能生成比原来更多的顶点。

12. **抗锯齿**

    锯齿的来源是因为场景的定义在三维空间中是连续的，而最终显示的像素则是一个离散的二维数组。所以判断一个点到底没有被某个像素覆盖的时候单纯是一个“有”或者“没有"问题，丢失了连续性的信息，导致锯齿。

    1. **SSAA：** 以4xSSAA 为例，假设最终屏幕输出的分辨率是 800x600，4xSSAA 就会先渲染到一个分辨率 1600x1200 的 buffer 上，然后再直接把这个放大 4 倍的 buffer 下采样至 800x600。这种做法在数学上是最完美的抗锯齿。但是劣势也很明显，光栅化和着色的计算负荷都比原来多了 4倍，render target 的大小也涨了 4 倍。
    2. **MSAA：** 在光栅化阶段，判断一个三角形是否被像素覆盖的时候会计算多个覆盖样本（Coverage sample），但是在 pixel shader 着色阶段计算像素颜色的时候每个像素还是只计算一次。下图以 4xMSAA 为例，每个像素包含有4个采样点，三角形只覆盖了 4 个 coverage sample 中的 2 个。每个像素只运行**一次**片段着色器。片段着色器所使用的顶点数据会插值到每个像素的**中心**，所得到的结果颜色会被储存在每个被遮盖住的子采样点中。然后对这些值进行平均作为该像素的颜色值，以减少锯齿效应。MSAA 在处理几何边缘时可能会产生伪像。

    <img src="https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202403151402993.png" style="zoom:10%;" />

    1. **FXAA：** 一种基于后处理的抗锯齿技术，其目标是在保持图像边缘细节的同时减少锯齿效应。FXAA 首先会检测图像中的高频变化，这通常表示了锯齿的存在。然后，它会对锯齿部分的像素进行模糊处理，以平滑边缘。FXAA 使用的模糊技术称为区域对角线化模糊（RDP - Rotated Grid Diagonal Processing）。它将图像的对角线区域模糊处理，从而减少锯齿，同时尽量保留高频细节。FXAA 的优势在于其计算开销相对较低，因为它是一个简单的后处理步骤。然而，它可能在处理高对比度边缘时引入一些模糊，因为它不是基于像素的实际几何形状进行抗锯齿。
    2. **TXAA（Temporal Antialiasing）：** 一种结合了时间上抗锯齿和空间上抗锯齿的技术，旨在提供高质量的图像边缘平滑效果。TXAA 使用多帧图像的信息来进行抗锯齿处理。它会对当前帧和前一帧之间的图像进行分析，以便更好地确定锯齿部分。TXAA 可以提供非常平滑的图像边缘，但可能会引入一些运动模糊，因为它依赖于时间上的多帧信息。由于 TXAA 需要对多帧图像进行分析和处理，因此它的计算开销相对较高，可能对性能产生影响。

    **离屏MSAA**

    由于GLFW负责了创建多重采样缓冲，启用MSAA非常简单。然而，如果我们想要使用我们自己的帧缓冲来进行离屏渲染，那么我们就必须要自己动手生成多重采样缓冲了。需要使用 **多重采样纹理附件** 和 **多重采样渲染缓冲对象**，渲染到多重采样帧缓冲对象的过程都是自动的。只要我们在帧缓冲绑定时绘制任何东西，光栅器就会负责所有的多重采样运算。我们最终会得到一个多重采样颜色缓冲以及/或深度和模板缓冲。因为多重采样缓冲有一点特别，我们不能直接将它们的缓冲图像用于其他运算，比如在着色器中对它们进行采样。

    一个多重采样的图像包含比普通图像更多的信息，我们所要做的是缩小或者还原(Resolve)图像。多重采样帧缓冲的还原通常是通过glBlitFramebuffer来完成，它能够将一个帧缓冲中的某个区域复制到另一个帧缓冲中，并且将多重采样缓冲还原。

    将一个多重采样的纹理图像不进行还原直接传入着色器也是可行的。GLSL提供了这样的选项，让我们能够对纹理图像的每个子样本进行采样，所以我们可以创建我们自己的抗锯齿算法。

13. **各种测试(缓冲)的含义，相对顺序？**

    （1）**深度测试：** 我们在观察物体的时候，位于前面的物体会把后面的物体挡住，所以在渲染的时候，图形管线会先对每一个位置的像素存储一个深度值，称为深度缓冲，代表了该像素点在3D世界中离相机最近物体的深度值。于是在计算每一个物体的像素值的时候，都会将它的深度值和缓冲器当中的深度值进行比较，如果这个深度值小于缓冲器中的深度值，就更新深度缓冲和颜色缓冲的值，否则就丢弃；简单来说，就是根据物体的深度决定是否渲染。

    （2）**Alpha测试：** 像素值一般是由RGBA四个分量来表示的，其中的A是alpha，表示的是物体的不透明度。1代表完全不透明，0代表完全透明。可选的 alpha 测试可在深度测试执行前在传入片段上运行。片段的 alpha 值与参考值作某些特定的测试（如等于，大于等），如果片段未能通过测试，它将不再进行进一步的处理。 alpha 测试经常用于不影响深度缓存的全透明片段的处理。简单来说，就是根据物体的透明度来决定是否渲染。Alpha测试会导致Early-Z失效，alphatest开了之后，会把某些本该写入的深度值丢弃，所以earlyz会失效。

    （3）**模板测试：** 模板缓冲是用于记录所呈现图元位置的离屏缓存，如果使用了模板缓冲，就相当于在屏幕上有一块模板盖在上面，只有位于这个模板中的图元片段，才会被渲染出来。模板测试就是用片段指定的参考值与模板缓冲中的模板值进行比较，如果达到预设的比较结果，模板测试就通过了，然后用这个参考值更新模板缓冲中的模板值；如果没有达到预设的比较结果，就是没有通过测试，就不更新模板缓冲。简单来说，就是根据物体的位置范围决定是否渲染。

    （4）**裁剪测试：** 在裁剪测试中，允许程序员开设一个裁剪框，只有在裁剪框内的片元才会被显示出来，在裁剪框外的片元皆被剔除。裁切测试可以避免当视口比屏幕窗口小时造成的渲染浪费问题。通常情况下，我们会让视口的大小和屏幕空间一样大，此时可以不需要使用到裁切测试。但当两者大小不一样大时，我们需要用到裁切测试来避免其产生的一些问题。

    （5）各种测试的相对顺序：**裁剪->Alpha->模板->深度**。

14. **Early-Z和Pre-Z**

    **Early-Z**：在最原始的渲染流程中，会先渲染A。再渲染B，在渲染B的时候会比较当前渲染的像素的深度和深度缓冲的值，如果通过深度测试则保留，没有通过深度测试则会被丢弃，这时就会带来浪费。当FragmentShader计算量越大的时候，这个浪费就会越明显，所以把深度比较这个事情放到FragmentShader前面进行，如果这个像素一开始就无法通过深度测试，那FragmentShader根本就不会计算它，使用EarlyZ机制来节省大量性能。但是开启Alpha Test都会使early z失效，所以当想要在渲染的时候使用AlphaTest的时候，就不能使用earlyZ优化了。所以把AlphaTest这个操作转移到其它地方去，比如PreDepthPass。

    **Pre-Z**：在UE中，首先先渲染一次PreDepthPass，这个Pass只渲染深度关闭颜色写入。在渲染Depth的时候就用AlphaTest把OpacityMask的区域像素的深度剔除掉。PrePass写深度的时候因为使用了AlphaTest，所以EarlyZ这个时候失效。然后再正常渲染，深度测试设置为Equal模式，正常渲染的时候没有使用AlphaTest，所以EarlyZ在这个时候起效。

15. **Phong模型和Blinn-Phong**

    Phong氏光照模型其实是经验模型，参数信息是通过经验得到的。Phong模型将物体光照分为三个部分进行计算，分别是：漫反射分量、镜面高光和环境光。其中，环境光分量是用来模拟全局光照效果的，其实就是在物体光照信息基础上叠加上一个较小的光照常量，用来表示场景中其他物体反射的间接光照。具体实现：环境分量，直接设置一个ambient分量，乘上光照颜色和物体颜色；漫反射分量，用光线到片段的向量与片段平面法线向量的点乘，乘上光的颜色和物体颜色；镜面分量，通过指数函数pow计算，有一个shininess分量，反光度越高，反射光的能力越强，散射得越少，高光点就会越小，用到了视线方向和反射光线方向的点积。

    冯氏光照不仅对真实光照有很好的近似，而且性能也很高。但是它的镜面反射会在一些情况下出现问题，特别是物体反光度很低时，会导致大片（粗糙的）高光区域，会在镜面高光区域的边缘出现一道很明显的断层。出现这个问题的原因是观察向量和反射向量间的夹角不能大于90度。如果点积的结果为负数，镜面光分量会变为0。这在大多数情况下都不是什么问题，因为观察方向离反射方向都非常远。然而，当物体的反光度非常小时，它产生的镜面高光半径足以让这些相反方向的光线对亮度产生足够大的影响。在这种情况下就不能忽略它们对镜面光分量的贡献了。解决办法是使用观察方向和光照方向的半程向量与法线的夹角。

    除此之外，冯氏模型与Blinn-Phong模型也有一些细微的差别：半程向量与表面法线的夹角通常会小于观察与反射向量的夹角。所以，如果你想获得和冯氏着色类似的效果，就必须在使用Blinn-Phong模型时将镜面反光度设置更高一点。通常我们会选择冯氏着色时反光度分量的2到4倍。

16. **Gamma矫正**

    过去，大多数监视器是阴极射线管显示器（CRT）。这些监视器有一个物理特性就是两倍的输入电压产生的不是两倍的亮度。输入电压产生约为输入电压的2.2次幂的亮度，这叫做监视器Gamma。

    Gamma也叫灰度系数，每种显示设备都有自己的Gamma值，都不相同，有一个公式：设备输出亮度 = 电压的Gamma次幂，任何设备Gamma基本上都不会等于1，等于1是一种理想的线性状态，这种理想状态是：如果电压和亮度都是在0到1的区间，那么多少电压就等于多少亮度。对于CRT，Gamma通常为2.2，因而，输出亮度 = 输入电压的2.2次幂，你可以从本节第二张图中看到Gamma2.2实际显示出来的总会比预期暗，相反Gamma0.45就会比理想预期亮，如果将Gamma0.45叠加到Gamma2.2的显示设备上，便会对偏暗的显示效果做到校正。

17. **法线贴图为什么偏蓝紫色？**

    法线贴图存储的是模型该顶点的切线空间下法线方向。切线空间的 Z 轴是顶点法线方向， X 轴是顶点的切线方向，Y 轴是副切线方向，可通过 X 轴和 Z 叉乘得到该方向。切线空间下法线每个坐标轴的取值范围是在（-1，1）。而存储为法线纹理图片的颜色取值范围是在（0，1）之间。需要通过（normal + 1）/  2，将取值范围从（-1，1）映射到（0，1）。由于大部分法线直指屏幕外，即（0， 0，1）对应RGB（0.5，0.5，1.0）
    所以法线贴图大多是蓝紫色。

18. **HDR**

    当存储在帧缓冲(Framebuffer)中时，亮度和颜色的值是默认被限制在0.0到1.0之间的，但是如果我们遇上了一个特定的区域，其中有多个亮光源使这些数值总和超过了1.0，那么这些片段中超过1.0的亮度或者颜色值会被约束在1.0，从而导致场景混成一片，难以分辨。由于大量片段的颜色值都非常接近1.0，在很大一个区域内每一个亮的片段都有相同的白色。这损失了很多的细节，使场景看起来非常假。显示器被限制为只能显示值为0.0到1.0间的颜色，但是在光照方程中却没有这个限制。通过使片段的颜色超过1.0，我们有了一个更大的颜色范围，这也被称作**HDR(High Dynamic Range, 高动态范围)**。有了HDR，亮的东西可以变得非常亮，暗的东西可以变得非常暗，而且充满细节。HDR允许用更大范围的颜色值渲染从而获取大范围的黑暗与明亮的场景细节，最后将所有HDR值转换成在[0.0, 1.0]范围的LDR(Low Dynamic Range,低动态范围)。转换HDR值到LDR值得过程叫做色调映射(Tone Mapping)。色调映射是一个损失很小的转换浮点颜色值至我们所需的LDR[0.0, 1.0]范围内的过程。

19. **什么是延迟渲染？G-buffer要存几张贴图？**

    （1）延迟渲染首先将物体的几何信息(位置、法线、颜色、镜面值）存到几何缓冲区中（即Geometric Buffer，G-Buffer）中，然后在光照处理阶段，使用G-Buffer中的纹理数据，对每个片段进行光照计算；这种渲染方法一个很大的好处就是能保证在G-Buffer中的片段和在屏幕上呈现的像素所包含的片段信息是一样的，因为深度测试已经最终将这里的片段信息作为最顶层的片段。这样保证了对于在光照处理阶段中处理的每一个像素都只处理一次。也就是说延迟渲染基本思想是，先执行深度测试，再进行着色计算，将本来在物体空间（三维空间）进行光照计算放到了屏幕空间（二维空间）进行处理。

    2）在每一帧当中G-buffer存储的信息有：位置、法线、颜色值、镜面值（所以其实有三张纹理，分别存位置、法线和颜色+镜面值(RGB+)A)；如果是PBR，应该还要再存一个金属度和粗糙度贴图。

20. **延迟渲染和正向渲染的区别，优缺点？**

    （1）区别：正向渲染，先执行着色计算，再执行深度测试；渲染n个物体在m个光源下的着色，复杂度为O（n*m），光源数量对计算复杂度影响大；对于正向渲染，我们通常会对一个像素运行多次片段着色器；延迟渲染，先进行深度测试，再执行着色计算；对于延迟渲染，每一个像素只会执行一次片段着色器。

    （2）优点：将光源的数目和场景中物体的数目在复杂度层次上完全分开。渲染n个物体在m个光源下的着色，复杂度为O（n+m），只渲染可见的像素，节省计算量；

    （3）缺点：MSAA在延迟渲染中不适用。因为延迟管线在生在Gbuffer阶段就已经被rasterize，无法确定其几何边缘，从而无法超采样，且其几何渲染输出的为光照前数据，包含诸如Albedo、法线、金属度、粗糙度等多种数据，会使用远多于前向渲染的缓冲区，将这些缓冲区全部增大数倍甚至十数倍（如16xMSAA），对GPU显存的开销极大，而且大大增加了深度测试所需读写的数据量，以及PS着色器需要写入的数据量，使得渲染性能也降低。

    ![img](https://pic1.zhimg.com/v2-689b31fbb3f9749bf87964d7cff25b7c_r.jpg)

21. **什么是PBR**

    答：基于物理的渲染（Physically Based Rendering，PBR）是指使用基于物理的原理和微平面理论建模的着色/光照模型，以及使用从现实中测量的表面参数来准确表示真实世界材质的渲染理念。可以直接以物理参数为依据来编写表面材质，而不必依靠粗劣的修改与调整来让光照效果看上去正常。使用基于物理参数的方法来编写材质还有一个更大的好处，就是不论光照条件如何，这些材质看上去都会是正确的，而在非PBR的渲染管线当中有些东西就不会那么真实了。

    必须满足以下三个条件：

    1. 基于微平面(Microfacet)的表面模型。
    2. 能量守恒。
    3. 应用基于物理的BRDF。

22. **微平面理论**

    答：一个平面越是粗糙，这个平面上的微平面的排列就越混乱。这些微小镜面这样无序取向排列的影响就是，当我们特指镜面光/镜面反射时，入射光线更趋向于向完全不同的方向发散(Scatter)开来，进而产生出分布范围更广泛的镜面反射。而与之相反的是，对于一个光滑的平面，光线大体上会更趋向于向同一个方向反射，造成更小更锐利的反射。

23. **粗糙度**

    答：粗糙度（roughness）来计算出众多微平面中，朝向方向沿着**某个向量（半程向量）**方向的比例，微平面的朝向方向与半程向量的方向越是一致，镜面反射的效果就越是强烈越是锐利。

24. **辐射率（Radiance）和辐照度（Irradiance）**

    答：辐射率（L）和辐照度（E）的区别：想象一个微小的平面，往每一个方向方向吸收光能，那么radiance就表示该平面沿着某一个方向上吸收到的光能，这个微小发光面吸收到的所有能量之和就是Irradiance，等于所有radiance的积分。Radiance是带有方向性的光亮度，Irradiance是不带有方向性的，各个方向上Radiance的积分之和。

25. **渲染方程/反射方程**

    答：渲染方程是一个描述光能在场景中流转的方程，它基于能量守恒定律，在理论上给出了一个完美的光能求解结果。其含义是：在某个视点看向特定的位置x，看到的出射光亮度(辐射率)*Lo*等于*x*点的自发光亮度*Le*(辐射率)以及该点的反射光亮度之和。

26. **BRDF**

    答：BRDF(Bidirectional Reflectance Distribution Function)，译作双向反射分布函数，是一个用来描述物体表面如何反射光线的方程，是出射光辐射率(Radiance)的微分和入射光辐照度(Irradiance)的微分之比。入射光 *l* 照到物体表面上，反射光线为*v*，那么反射光的亮度（辐射率L）和入射光的能量(辐照度E)会成一个比例，而这个比例就是BRDF。可以理解为，在某一个特定的角度观看某个点时，各个方向的入射光对该点的最终光亮度产生的贡献比例，其实它就是一些零点几的小数。BRDF可以近似的求出每束光线对一个给定了材质属性的平面上最终反射出来的光线所作出的贡献程度。

    ![cook-torrance brdf](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202403151405953.png)

    ![brdf镜面反射](https://cdn.jsdelivr.net/gh/qzlu-cyber/PicgoLib@main/images/202403151406127.png)

    - **D(法线分布函数)：估算在受到表面粗糙度的影响下，朝向方向与半程向量一致的微平面的数量；**
    - **F(菲涅尔项)：描述的是被反射的光线对比光线被折射的部分所占的比率，这个比率会随着观察的角度不同而不同。当光线碰撞到一个表面的时候，菲涅尔方程会根据观察角度告诉我们被反射的光线所占的百分比。利用这个反射比率和能量守恒原则，我们可以直接得出光线被折射的部分以及光线剩余的能量。**
    - **G(几何函数)：描述了微平面自成阴影的属性。当一个平面相对比较粗糙的时候，平面表面上的微平面有可能挡住其他的微平面从而减少表面所反射的光线。**

27. **PBR的计算**

    答：**漫反射部分**：lambert项是一个常量值，直接积分即可，通过环境立方体贴图来获取每个方向的辐射率（radiance），然后对于每个出射方向Lo的漫反射积分结果，预计算存储到一张辐照度贴图中（通过对radiance的卷积），在实时渲染时直接通过出射方向采样该辐照度贴图即可求得漫反射部分的结果。

    **流程：** 需要对环境立方体贴图预计算-->PBR要求实际物理属性-->常规的环境立方体贴图是LDR的-->但是最终的L0可能会大于1，如果不在 HDR 渲染环境中工作，就无法正确指定每个光的相对强度-->HDR文件格式的贴图-->等距柱状投影图-->渲染到立方体贴图(envCubemap)上-->成功读取 HDR 环境贴图，并将 HDR 立方体贴图作为天空盒渲染到了场景中；现在，为了生成辐照度贴图，需要将环境光照求卷积，转换为立方体贴图。创建立方体贴图-->黎曼和对envCubemap求卷积-->得到预计算好的辐照度图。

    **镜面反射部分：**通过**分割近似求和法**可以将这个积分划分为两个卷积式子。卷积的第一部分被称为**预滤波环境贴图**，它类似于辐照度图，是预先计算的环境卷积贴图，但这次考虑了粗糙度。因为随着粗糙度的增加，参与环境贴图卷积的采样向量会更分散，导致反射更模糊，所以对于卷积的每个粗糙度级别，按顺序把模糊后的结果存储在预滤波贴图的 mipmap 中，不同的粗糙度对应着不同的mipmap级别，处于中间程度的粗糙度可以插值。第二部分称为**BRDF部分**，它可以进一步拆分为菲涅尔项有关的两部分，分别代表菲涅尔响应的**比例**和**偏差**，然后对这两项做卷积预计算，并存到一张查找贴图中(look-up texture，LUT)。渲染时可以将n·wi作为横坐标，以粗糙度roughness作为纵坐标，去LUT中采样获得该条件下的BRDF响应结果，以加快计算速度。

    **总结：** PBR计算结果的漫反射部分，通过卷积存到一张辐照度图当中，该辐照度图是一个立方体贴图，表示了每一个出射光线采样得到的漫反射积分计算结果；镜面反射部分通过分割近似求和法，划分为两个卷积式子，第一部分计算结果存到一张预滤波环境贴图中，将不同粗糙度的卷积结果存在一张Mipmap贴图中；第二部分称为BRDF部分：以n·wi作为横坐标，以粗糙度roughness作为纵坐标，就可以从查找贴图中采样获得该条件下的BRDF响应结果；

28. **PBR漫反射部分为什么要除以一个π？**

    答：如果散射的光线最后都能汇集到一点的话，积分的结果就是会再乘一个π。所以分散的时候就需要除π。

29. **什么是LUT？**

    答：look-up texture，是一个查找纹理，称为BRDF积分贴图。在计算PBR的镜面反射部分时，会将它的第二部分积分结果，也就是BRDF项，进一步拆分为跟菲涅尔项有关的两部分，分别代表菲涅尔响应的比例和偏差，然后对这两项做卷积预计算，并存到这张LUT中，LUT的输入是cosθ和粗糙度，输出结果是菲涅尔响应的系数和偏差，在渲染时可以直接通过cosθ和粗糙度来采样获得BRDF的响应结果，加快计算速度。

##### 光线追踪

- **基本思想**

  光线追踪方法主要思想是从视点向成像平面上的像素发射光线，找到与该光线相交的最近物体的交点，如果该点处的表面是散射面，则计算光源直接照射该点产生的颜色:如果该点处表面是镜面或折射面，则继续向反射或折射方向跟踪另一条光线，如此递归下去，直到光线逃逸出场景或达到设定的最大递归深度。

##### **路径追踪**

- 提出背景

  由于光追没有考虑漫反射物体的随机反射，而是直接计算着色，停止反射了。但实际上漫反射物体也会向各个方向反射光线，所以引出了路径追踪。

- 基本思想

  路径追踪的基本思想是从视点发出一条光线，光线与物体表面相交时根据表面的材质属性继续采样一个方向（选择一个随机方向），发出另一条光线，如此迭代，直到光线打到光源上（或逃逸出场景），然后用蒙特卡洛的方法，计算其贡献，作为像素的颜色值；由于单条光路的蒙特卡洛积分肯定会不准确，产生很多噪点，所以一般是单个像素发射多条光线进行路径追踪，一条路径就是视点和场景中各个物体反射交点的连线。

##### 其他

1. **如果一个像素点在Shadow Map中找不到，会怎么处理？**

   答：如果在Shadow Map中找不到一个像素点对应的深度值，这通常意味着该点要么不在光源能照射到的区域内，要么是因为Shadow Map的分辨率限制而无法精确映射到具体的深度值。

   **视为在阴影之外**：如果一个点在Shadow Map中找不到对应的深度值，可以简单地假设这个点不在阴影中。这种方法简单直接，但可能会导致阴影边缘出现不真实的锯齿效果，特别是当Shadow Map分辨率较低时。

   **优化Shadow Map的分辨率和覆盖范围**：通过调整Shadow Map的大小和从光源视角覆盖的区域，可以减少找不到对应深度值的情况。例如，使用Cascaded Shadow Maps技术可以根据距离光源的不同距离来使用不同的Shadow Map，从而在保持性能的同时提高近处物体的阴影质量。

2. **多个光源的阴影怎么处理？**

   答：（1）**对每个光源单独生成阴影图**。最直接的方法是对每个光源都生成一个阴影图（Shadow Map）。这意味着每个光源都需要从光源的视角渲染场景一次，以捕捉影响场景中物体的阴影信息。然后，在渲染场景的最终图像时，需要考虑所有光源的阴影图来确定每个像素是否处于阴影中。

   ​        （2）**阴影的累积和混合**。当场景中存在多个光源时，一个像素点可能同时被多个光源照射，也可能同时处于多个光源产生的阴影中。因此，在渲染阶段，需要综合考虑所有光源对每个像素的贡献。这通常通过将每个光源产生的阴影贡献进行适当的累积和混合来实现。

3. **如何在CPU端减少drawCall？**

   - **批处理（Batching）**：将多个渲染任务组合成一个大的批次，以单个draw call执行。
   - **实例化渲染（Instancing）**：当需要渲染多个结构和材质相同但在世界中位置不同的对象时，可以使用实例化渲染。这种方法只需要一个draw call就可以渲染所有实例，极大地减少了draw call的数量。
   - **静态和动态合并（Static and Dynamic Batching）**：
     - **静态合并**：在游戏或应用启动时，提前将多个静态物体（不会在运行时改变的物体）合并为一个大的网格。
     - **动态合并**：在运行时动态地将多个动态物体（可能会移动或变化的物体）合并为单个网格进行渲染。

4. **法线可视化**

   利用几何着色器，几何着色器（几何着色器接受的位置向量是观察空间坐标）接收一个三角形图元，并沿着法向量生成三条线——每个顶点一个法向量，再使用片段着色器输出颜色。